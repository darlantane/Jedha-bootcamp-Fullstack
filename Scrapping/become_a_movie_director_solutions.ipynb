{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "Save the following code in a file named `imdb1.py`. ‚¨áÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "filename = \"imdb.json\"\n",
    "\n",
    "class IMDbSpider(scrapy.Spider):\n",
    "    name = \"imdb_movies\"\n",
    "    start_urls = ['https://www.imdb.com/chart/top/']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \n",
    "        for movie in response.css(\".ipc-metadata-list-summary-item\"):\n",
    "            # Title and rank\n",
    "            title_and_rank = movie.css(\"h3.ipc-title__text::text\").get()\n",
    "            rank, title = (title_and_rank.split(\". \", 1) if title_and_rank else (None, None))\n",
    "\n",
    "            # Movie URL\n",
    "            url = movie.css(\"a.ipc-title-link-wrapper::attr(href)\").get()\n",
    "            full_url = response.urljoin(url) if url else None\n",
    "\n",
    "            # Rating\n",
    "            rating = movie.xpath('.//span[contains(@class, \"ipc-rating-star--rating\")]/text()').get()\n",
    "\n",
    "            # Votes\n",
    "            votes = movie.xpath('.//span[@class=\"ipc-rating-star--voteCount\"]//text()').getall()\n",
    "            votes = votes[1].strip('\"()')\n",
    "\n",
    "            # Yield the result\n",
    "            yield {\n",
    "                \"rank\": rank,\n",
    "                \"title\": title,\n",
    "                \"url\": full_url,\n",
    "                \"rating\": rating,\n",
    "                \"votes\": votes,\n",
    "            }\n",
    "\n",
    "\n",
    "process = CrawlerProcess(settings = {\n",
    "    'USER_AGENT': 'Chrome/97.0',\n",
    "    \"FEEDS\": {\n",
    "        '01-Become_a_movie_director/' + filename : {\"format\": \"json\"},\n",
    "    },\n",
    "})\n",
    "\n",
    "process.crawl(IMDbSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Optional üí™üí™\n",
    "\n",
    "Save the following code in a file named `imdb2.py`. ‚¨áÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import logging\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "my_file = open(\"01-Become_a_movie_director/url_list.txt\", \"r\")\n",
    "content = my_file.read()\n",
    "content_list = content.split(\"\\n\")[:-1]\n",
    "\n",
    "class imdb_spider(scrapy.Spider):\n",
    "    # Name of your spider\n",
    "    name = \"imdb\"\n",
    "\n",
    "    # Url to start your spider from \n",
    "    start_urls = content_list\n",
    "    # Callback function that will be called when starting your spider\n",
    "    # It will get text, author and tags of the first <div> with class=\"quote\"\n",
    "    # //*[@id=\"main\"]/div/span/div/div/div[3]/table/tbody/tr[250]/td[2]/a\n",
    "    # //*[@id=\"main\"]/div/span/div/div/div[3]/table/tbody/tr[1]/td[2]/a\n",
    "    def parse(self, response):\n",
    "        return {\n",
    "            \"title\": response.xpath('/html/body/div[2]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/h1/text()').get(),\n",
    "            \"url\": response.request.url,\n",
    "            \"cast\": [\n",
    "                {\n",
    "                    \"actor\" : element.xpath(\"div[2]/a/text()\").get(),\n",
    "                    \"role\" : element.xpath(\"div[2]/div/ul/li/a/span[1]/text()\").get()\n",
    "                }\n",
    "                for element in response.xpath('//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/div[2]/div[2]/div')\n",
    "            ],\n",
    "            \"storyline\": response.xpath('/html/body/div[2]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[1]/div[1]/p/span[1]/text()').get(),\n",
    "            \"tags\": response.xpath('//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section/div[2]/div[2]/a/span/text()').getall()\n",
    "        }\n",
    "        \n",
    "\n",
    "# Name of the file where the results will be saved\n",
    "filename = \"imdb3.json\"\n",
    "\n",
    "# If file already exists, delete it before crawling (because Scrapy will \n",
    "# concatenate the last and new results otherwise)\n",
    "if filename in os.listdir('01-Become_a_movie_director/'):\n",
    "        os.remove('01-Become_a_movie_director/' + filename)\n",
    "\n",
    "# Declare a new CrawlerProcess with some settings\n",
    "## USER_AGENT => Simulates a browser on an OS\n",
    "## LOG_LEVEL => Minimal Level of Log \n",
    "## FEEDS => Where the file will be stored \n",
    "## More info on built-in settings => https://docs.scrapy.org/en/latest/topics/settings.html?highlight=settings#settings\n",
    "process = CrawlerProcess(settings = {\n",
    "    'USER_AGENT': 'Chrome/97.0',\n",
    "    'LOG_LEVEL': logging.INFO,\n",
    "    \"FEEDS\": {\n",
    "        '01-Become_a_movie_director/' + filename : {\"format\": \"json\"},\n",
    "    },\n",
    "    \"AUTOTHROTTLE_ENABLED\" : False\n",
    "})\n",
    "\n",
    "# Start the crawling using the spider you defined above\n",
    "process.crawl(imdb_spider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
